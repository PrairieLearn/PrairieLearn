import * as async from 'async';
import { OpenAI } from 'openai';
import { zodResponseFormat } from 'openai/helpers/zod.mjs';
import type { ChatCompletionMessageParam } from 'openai/resources/index.mjs';
import { z } from 'zod';

import { HttpStatusError } from '@prairielearn/error';

import { config } from '../../../lib/config.js';
import type {
  AssessmentQuestion,
  Course,
  InstanceQuestion,
  Question,
} from '../../../lib/db-types.js';
import { buildQuestionUrls } from '../../../lib/question-render.js';
import { createServerJob } from '../../../lib/server-jobs.js';
import * as questionServers from '../../../question-servers/index.js';
import {
  generateSubmissionMessage,
  selectInstanceQuestionsForAssessmentQuestion,
  selectLastVariantAndSubmission,
} from '../ai-grading/ai-grading-util.js';
import type { AIGradingLog, AIGradingLogger } from '../ai-grading/types.js';

import {
  insertDefaultAiSubmissionGroups,
  selectAiSubmissionGroups,
  updateAiSubmissionGroup,
} from './ai-submission-grouping-util.js';

const PARALLEL_SUBMISSION_GROUPING_LIMIT = 20;

const SUBMISSION_GROUPING_OPENAI_MODEL: OpenAI.Chat.ChatModel = 'gpt-5';

async function renderInstanceQuestionAnswerHtml({
  question,
  instance_question,
  course,
  urlPrefix,
}: {
  question: Question;
  instance_question: InstanceQuestion;
  course: Course;
  urlPrefix: string;
}) {
  const { submission, variant } = await selectLastVariantAndSubmission(instance_question.id);
  const locals = {
    ...buildQuestionUrls(urlPrefix, variant, question, instance_question),
    questionRenderContext: 'ai_grading',
  };
  const questionModule = questionServers.getModule(question.type);
  const render_submission_results = await questionModule.render(
    { question: false, submissions: false, answer: true },
    variant,
    question,
    submission,
    [submission],
    course,
    locals,
  );

  return render_submission_results.data.answerHtml;
}

/**
 * Given a question, the AI returns whether or not the student-provided final answer is correct.
 */
async function aiEvaluateStudentResponse({
  question,
  question_answer,
  instance_question,
  course,
  urlPrefix,
  openai,
}: {
  question: Question;
  question_answer: string;
  instance_question: InstanceQuestion;
  course: Course;
  urlPrefix: string;
  openai: OpenAI;
}) {
  const { submission, variant } = await selectLastVariantAndSubmission(instance_question.id);
  const locals = {
    ...buildQuestionUrls(urlPrefix, variant, question, instance_question),
    questionRenderContext: 'ai_grading',
  };
  const questionModule = questionServers.getModule(question.type);
  const render_submission_results = await questionModule.render(
    { question: false, submissions: true, answer: false },
    variant,
    question,
    submission,
    [submission],
    course,
    locals,
  );

  const submission_text = render_submission_results.data.submissionHtmls[0];

  const submissionMessage = generateSubmissionMessage({
    submission_text,
    submitted_answer: submission.submitted_answer,
    include_ai_grading_prompts: false,
  });

  // Prompt the LLM to determine if the submission is correct or not.
  const messages: ChatCompletionMessageParam[] = [
    {
      role: 'user',
      content: 'Start of student submission:',
    },
    submissionMessage,
    {
      role: 'user',
      content: 'End of student submission.',
    },
    {
      role: 'user',
      content: `CORRECT ANSWER: \n${question_answer}`,
    },
    {
      role: 'user',
      content: `
Identify the student's final answer. Then, identify the student's box answer. Consider the box answer. If the boxed answer exists, response = boxed answer. Else, response = final answer.

Does the student's response match the correct answer exactly? Must be PRECISELY mathematically equivalent to the answer as written.

Ensure that all parts of the correct answer are included. Any error in the response will disqualify it from being a correct answer.

If it seems AMBIGUOUS (e.g. a few answers are present, one answer erased out, crossed out), mark it incorrect.

Return a boolean corresponding to whether or not the student's response is equivalent to the correct answer.
      `,
    },
  ];

  const completion = await openai.chat.completions.parse({
    messages,
    model: SUBMISSION_GROUPING_OPENAI_MODEL,
    user: `course_${course.id}`,
    response_format: zodResponseFormat(
      z.object({
        correct: z.boolean(),
      }),
      'response-evaluation',
    ),
  });

  const completionContent = completion.choices[0].message.parsed;

  if (!completionContent) {
    throw new Error('No completion content returned from OpenAI.');
  }

  return completionContent.correct;
}

/**
 * Groups student submissions into AI submission groups based on exact match to the final answer.
 * Answers that match go into one group; those that donâ€™t are grouped separately.
 * Grouping checks for exact equivalence to the final answer, considering only the boxed or final answer.
 */
export async function aiSubmissionGrouping({
  course,
  course_instance_id,
  question,
  assessment_question,
  urlPrefix,
  authn_user_id,
  user_id,
  closed_instance_questions_only,
  instance_question_ids,
}: {
  question: Question;
  course: Course;
  course_instance_id?: string;
  assessment_question: AssessmentQuestion;
  urlPrefix: string;
  authn_user_id: string;
  user_id: string;
  closed_instance_questions_only: boolean;
  /**
   * Limit grading to the specified instance questions.
   * Only use when mode is 'selected'.
   */
  instance_question_ids?: string[];
}) {
  if (!config.aiGradingOpenAiApiKey || !config.aiGradingOpenAiOrganization) {
    throw new HttpStatusError(403, 'Feature not available.');
  }

  const openai = new OpenAI({
    apiKey: config.aiGradingOpenAiApiKey,
    organization: config.aiGradingOpenAiOrganization,
  });

  const serverJob = await createServerJob({
    courseId: course.id,
    courseInstanceId: course_instance_id,
    assessmentId: assessment_question.assessment_id,
    authnUserId: authn_user_id,
    userId: user_id,
    type: 'ai_submission_grouping',
    description: 'Perform AI submission grouping',
  });

  const instanceQuestionIdsSet: Set<string> = instance_question_ids
    ? new Set(instance_question_ids)
    : new Set();

  serverJob.executeInBackground(async (job) => {
    if (!assessment_question.max_manual_points) {
      job.fail('The assessment question has no manual grading');
    }

    const allInstanceQuestions = await selectInstanceQuestionsForAssessmentQuestion(
      assessment_question.id,
      closed_instance_questions_only,
    );

    const selectedInstanceQuestions =
      instanceQuestionIdsSet.size > 0
        ? allInstanceQuestions.filter((q) => instanceQuestionIdsSet.has(q.id))
        : allInstanceQuestions;

    job.info(`Grouping ${selectedInstanceQuestions.length} instance questions...`);

    await insertDefaultAiSubmissionGroups({
      assessment_question_id: assessment_question.id,
    });

    const submissionGroups = await selectAiSubmissionGroups({
      assessmentQuestionId: assessment_question.id,
    });

    const likelyCorrectGroup = submissionGroups.find(
      (g) => g.submission_group_name === 'Likely Correct',
    );
    const reviewNeededGroup = submissionGroups.find(
      (g) => g.submission_group_name === 'Review Needed',
    );

    if (!likelyCorrectGroup) {
      throw new Error(
        `Missing 'Likely Correct' submission group for assessment question ${assessment_question.id}`,
      );
    }

    if (!reviewNeededGroup) {
      throw new Error(
        `Missing 'Review Needed' submission group for assessment question ${assessment_question.id}`,
      );
    }

    let index = 1;
    const groupInstanceQuestion = async (
      total: number,
      instance_question: InstanceQuestion,
      logger: AIGradingLogger,
    ) => {
      const answerHtml = await renderInstanceQuestionAnswerHtml({
        question,
        instance_question,
        course,
        urlPrefix,
      });

      if (!answerHtml) {
        logger.error(
          `Instance question ${instance_question.id} has no answer. Ensure that every instance question has an answer in pl-answer-panel.`,
        );
        return false;
      }

      const submissionIsLikelyCorrect = await aiEvaluateStudentResponse({
        question,
        question_answer: answerHtml,
        instance_question,
        course,
        urlPrefix,
        openai,
      });

      await updateAiSubmissionGroup({
        instance_question_id: instance_question.id,
        ai_submission_group_id: submissionIsLikelyCorrect
          ? likelyCorrectGroup.id
          : reviewNeededGroup.id,
      });
      logger.info(`Grouped instance question ${instance_question.id} (${index}/${total})`);
      index += 1;
      return true;
    };

    const instance_question_grouping_successes = await async.mapLimit(
      selectedInstanceQuestions,
      PARALLEL_SUBMISSION_GROUPING_LIMIT,
      async (instanceQuestion) => {
        const logs: AIGradingLog[] = [];
        const logger: AIGradingLogger = {
          info: (msg: string) => {
            logs.push({
              messageType: 'info',
              message: msg,
            });
          },
          error: (msg: string) => {
            logs.push({
              messageType: 'error',
              message: msg,
            });
          },
        };

        try {
          return await groupInstanceQuestion(
            selectedInstanceQuestions.length,
            instanceQuestion,
            logger,
          );
        } catch (err) {
          logger.error(err);
        } finally {
          for (const log of logs) {
            if (log.messageType === 'info') {
              job.info(log.message);
            } else if (log.messageType === 'error') {
              job.error(log.message);
            }
          }
        }
      },
    );

    const error_count = instance_question_grouping_successes.filter((success) => !success).length;

    if (error_count > 0) {
      job.error('Number of errors: ' + error_count);
      job.fail('Errors occurred during AI submission grouping, see output for details');
    } else {
      job.info('AI submission grouping completed successfully');
    }
  });
  return serverJob.jobSequenceId;
}
