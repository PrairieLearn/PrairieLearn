<div class="d-flex justify-content-center">
  <div class="card mb-4" style="width: 80%">
    <div class="card-body bg-light">
      Morphew, J. W., Silva, M., Herman, G., and West, M.,
      <b
        >"Frequent mastery testing with second-chance exams leads to enhanced student learning in
        undergraduate engineering"</b
      >, <i>Applied Cognitive Psychology</i> 34(1), 2020. DOI:
      <a href="https://doi.org/10.1002/acp.3605">10.1002/acp.3605</a>. Full-text link:
      <a href="http://lagrange.mechse.illinois.edu/pubs/MoSiHeWe2020/MoSiHeWe2020.pdf">PDF</a>.
    </div>
  </div>
</div>

<p>
  In this recently published paper,
  <a href="https://engineering.purdue.edu/ENE/People/ptProfile?resource_id=222158">Jason Morphew</a>
  and co-authors showed that frequent short PrairieLearn exams in the CBTF (Computer-Based Testing
  Facility) substantially increased student learning in TAM 251 ("Introductory Solid Mechanics") at
  the University of Illinois. Most impressively, these learning gains were on an identical
  pen-and-paper final exam and there were improvements at both high and low grade levels.
</p>

<p>
  <b>How did TAM 251 use the CBTF?</b> In previous semesters the course used a
  <i>traditional exam schedule</i> with two pen-and-paper midterm exams.
  <a href="https://mfsilva.web.illinois.edu">Mariana Silva</a> converted it to a
  <i>frequent exam schedule</i> with seven short CBTF exams and seven optional second-chance retry
  exams (see Figure 1). The new exams were all implemented in PrairieLearn and allowed students to
  re-attempt questions for partial credit, with a mastery grading scheme that only awarded points
  for correct answers.
</p>

<div class="d-flex justify-content-center">
  <div class="card border-1 mt-2 mb-4" style="width: 90%">
    <div class="text-center m-4">
      <a href="exam_schedule.png"
        ><img
          src="exam_schedule.png"
          class="card-img-top"
          alt="Traditional versus frequent exam schedules."
      /></a>
    </div>
    <div class="card-body d-flex justify-content-center bg-light">
      <p class="card-text">
        <b>Figure 1:</b> Traditional versus frequent exam schedule in TAM 251.
      </p>
    </div>
  </div>
</div>

<p>
  <b>How was learning measured?</b> Two semesters were compared, one using the traditional exam
  schedule and the other using frequent exams. Both semesters finished with an identical
  pen-and-paper final exam that consisted of 13 multiple-choice questions and three free-response
  questions in the given–find–solution format. In each semester all students took the exam at the
  same time in a proctored facility and the exam papers were kept secret and never released to
  students. The exam was hand-graded using an identical detailed rubric in each semester. The
  statistical analysis controlled for the ability of the incoming student population using grades in
  the prerequisite course.
</p>

<p>
  <b>How much did student learning improve?</b> Students using the frequent exam schedule scored 7%
  higher on average (about 2/3 of a letter grade) on the final exam. This resulted in twice the
  number of A grades on the final and a drop of 60% in D and F grades (see Figure 2). The
  improvement was actually higher on the free-response questions (+11.3 percentage points) than the
  multiple-choice questions (+3.5 points), despite the fact that students had not practiced
  pen-and-paper free-response questions before in this class. There were over 200 students in each
  of the traditional- and frequent-exam semesters so all the results are statistically significant.
  As detailed in the paper, women and minority students had the same increases as the rest of the
  population.
</p>

<div class="d-flex justify-content-center">
  <div class="card border-1 mt-2 mb-4" style="width: 80%">
    <div class="text-center m-4">
      <a href="exam_score_dist.png"
        ><img
          src="exam_score_dist.png"
          class="card-img-top"
          style="max-width: 40rem"
          alt="Histogram of exam scores."
      /></a>
    </div>
    <div class="card-body d-flex justify-content-center bg-light">
      <p class="card-text">
        <b>Figure 2:</b> Histogram of student results on the identical pen-and-paper final exam for
        the two semesters. Exam letter grades correspond to the following exam score ranges: A (90%
        or higher), B (80% to 90%), C (70% to 80%), and D/F (below 70%). Error bars show 95%
        confidence intervals.
      </p>
    </div>
  </div>
</div>

<p>
  <b>What's the theory behind these results?</b> Overall, it seems likely that students both study
  more and use more effective study strategies when given frequent tests, for at least three
  reasons. First, having many small exams essentially forces students to use
  <a href="https://en.wikipedia.org/wiki/Distributed_practice">distributed practice</a> rather than
  cramming. Second, testing is simply more effective at solidifying memory than just studying (the
  <a href="https://en.wikipedia.org/wiki/Testing_effect">testing effect</a> in psychology). Third,
  second-chance exams and mastery grading encourage students to learn from their errors on the
  first-chance exams, rather than simply dismissing the results as a fluke or the result of an
  unfair test, thereby improving
  <a href="https://en.wikipedia.org/wiki/Metacognition">metacognition</a>.
</p>

<div class="alert alert-secondary">
  This post is also available at
  <a href="https://edatscale.org/2020/02/26/learning-gains-from-frequent-computerized-exams/"
    >edatscale.org</a
  >
</div>
